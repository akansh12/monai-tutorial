{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akansh12/monai-tutorial/blob/main/MONAI/MONAI_tutorial(3D_seg).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn9T3nCLm2_o",
        "outputId": "cdd3892a-6cb2-4b13-ece9-d0e100a7d197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "ModuleNotFoundError: No module named 'monai'\n",
            "\u001b[K     |████████████████████████████████| 816 kB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[pillow, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrQok6XMnzRv"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "from glob import glob\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import monai\n",
        "from monai.data import create_test_image_3d, list_data_collate, decollate_batch\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    AsChannelFirstd,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    RandCropByPosNegLabeld,\n",
        "    RandRotate90d,\n",
        "    ScaleIntensityd,\n",
        "    EnsureTyped,\n",
        "    EnsureType\n",
        ")\n",
        "\n",
        "from monai.visualize import plot_2d_or_3d_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7XOB025sJ8r"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5YznJ_Jphsy",
        "outputId": "8e38d90f-6755-4065-e4fd-8850d289cac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating synthetic data to ./temp_file (this may take a while)\n"
          ]
        }
      ],
      "source": [
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "os.makedirs(\"./temp_file\")\n",
        "tempdir = \"./temp_file\"\n",
        "print(f\"generating synthetic data to {tempdir} (this may take a while)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK1QH0Iupn0l"
      },
      "outputs": [],
      "source": [
        "for i in range(40):\n",
        "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1, channel_dim=-1)\n",
        "\n",
        "    n = nib.Nifti1Image(im, np.eye(4))\n",
        "    nib.save(n, os.path.join(tempdir, f\"img{i:d}.nii.gz\"))\n",
        "\n",
        "    n = nib.Nifti1Image(seg, np.eye(4))\n",
        "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O84lEzyluO9s",
        "outputId": "55b56efe-597c-4ca4-db32-73f1f303afc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 128, 128, 1)\n",
            "[0.         0.56419837 0.58732367 0.75521755 0.77602738 0.85623723\n",
            " 0.88002145 0.90849024 0.9440394  0.96790183 1.        ]\n"
          ]
        }
      ],
      "source": [
        "eg = nib.load(\"/content/temp_file/img13.nii.gz\")\n",
        "eg_data = eg.get_fdata()\n",
        "print(eg_data.shape)\n",
        "print(np.unique(eg_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTyiOx13zHdQ",
        "outputId": "5b7085ee-1412-4cf7-881f-87265da2d70f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 128, 128, 1)\n",
            "[0. 1.]\n"
          ]
        }
      ],
      "source": [
        "eg = nib.load(\"/content/temp_file/seg13.nii.gz\")\n",
        "eg_data = eg.get_fdata()\n",
        "print(eg_data.shape)\n",
        "print(np.unique(eg_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1SBazY2skgj"
      },
      "outputs": [],
      "source": [
        "images = sorted(glob(os.path.join(tempdir, \"img*.nii.gz\")))\n",
        "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
        "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[:20], segs[:20])]\n",
        "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[-20:], segs[-20:])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp-rLn7Lu2H4"
      },
      "outputs": [],
      "source": [
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
        "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
        "        ScaleIntensityd(keys=\"img\"),\n",
        "        # RandCropByPosNegLabeld(\n",
        "        #     keys=[\"img\", \"seg\"], label_key=\"seg\", spatial_size=[128, 128, 376], pos=1, neg=1, num_samples=4\n",
        "        # ),\n",
        "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 2]),\n",
        "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
        "    ]\n",
        ")\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
        "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
        "        ScaleIntensityd(keys=\"img\"),\n",
        "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0YTUDvvvtHx",
        "outputId": "a6e9a63a-2a12-4e7f-ddf0-3b912903d907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 128, 128, 128]) torch.Size([2, 1, 128, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
        "check_loader = DataLoader(check_ds, batch_size=2, num_workers=2, collate_fn=list_data_collate)\n",
        "check_data = monai.utils.misc.first(check_loader)\n",
        "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h27KAzi6v2Fa"
      },
      "outputs": [],
      "source": [
        "train_ds = monai.data.Dataset(data = train_files, transform = train_transforms)\n",
        "train_loader = DataLoader(train_ds, \n",
        "                          batch_size = 2,\n",
        "                          shuffle = True,\n",
        "                          num_workers = 2,\n",
        "                          collate_fn = list_data_collate,\n",
        "                          pin_memory=torch.cuda.is_available())\n",
        "\n",
        "val_ds = monai.data.Dataset(data = val_files, transform = val_transforms)\n",
        "val_loader = DataLoader(val_ds, \n",
        "                          batch_size = 1,\n",
        "                          shuffle = False,\n",
        "                          num_workers = 2,\n",
        "                          collate_fn = list_data_collate,\n",
        "                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cyX3MvDwYqw"
      },
      "outputs": [],
      "source": [
        "dice_metric = DiceMetric(include_background=True, reduction = 'mean', get_not_nans=False)\n",
        "post_trans = Compose([EnsureType(), Activations(sigmoid = True), AsDiscrete(threshold=0.5)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcvI6HAFwYt5"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = monai.networks.nets.UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    channels=(32, 64, 128, 256, 512),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PJ-i3eNwYwO"
      },
      "outputs": [],
      "source": [
        "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8d430dff3871498f83db1500da65f446",
            "3bf1fccd0e274bacb5ed150cdb24026a",
            "e4a165ddccf64071a04a8b694bb85351",
            "67bd4ad7be414fa5a74791985b25fb2c",
            "e8acf37225d54deeb1bfb0cbf4621313",
            "2961ff35b95a42f39184dbe231d32dbd",
            "add8f7d021444065ad029a474361f445",
            "dec5306a9d7442cabeea8e675b61a87f"
          ]
        },
        "id": "41FC5VIj080E",
        "outputId": "f7df54ae-5f06-4dbc-f634-60474964258e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d430dff3871498f83db1500da65f446",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bf1fccd0e274bacb5ed150cdb24026a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 average loss: 0.7468\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4a165ddccf64071a04a8b694bb85351",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 average loss: 0.7012\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67bd4ad7be414fa5a74791985b25fb2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved new best metric model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8acf37225d54deeb1bfb0cbf4621313",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 average loss: 0.6802\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2961ff35b95a42f39184dbe231d32dbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 average loss: 0.6679\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "add8f7d021444065ad029a474361f445",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved new best metric model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dec5306a9d7442cabeea8e675b61a87f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 average loss: 0.6596\n",
            "train completed, best_metric: 0.9258 at epoch: 4\n"
          ]
        }
      ],
      "source": [
        "val_interval = 2\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = list()\n",
        "metric_values = list()\n",
        "writer = SummaryWriter()\n",
        "\n",
        "for epoch in tqdm(range(40)):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  step = 0\n",
        "  for batch_data in tqdm(train_loader):\n",
        "    step += 1\n",
        "    inputs, labels = batch_data['img'].to(device),batch_data['seg'].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_function(outputs,inputs)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_len = len(train_ds) // train_loader.batch_size\n",
        "    writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "  epoch_loss /= step\n",
        "  epoch_loss_values.append(epoch_loss)\n",
        "  print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "  if (epoch + 1) % val_interval == 0:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_images = None\n",
        "      val_labels = None\n",
        "      val_outputs = None\n",
        "\n",
        "      for val_data in tqdm(val_loader):\n",
        "        val_images, val_labels = val_data['img'].to(device),val_data['seg'].to(device)\n",
        "        # roi_size = (128,128,128)\n",
        "        # sw_batch_size = 4\n",
        "        # val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
        "        # val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
        "        val_outputs = post_trans(model(val_images))\n",
        "\n",
        "\n",
        "        dice_metric(y_pred = val_outputs, y =val_labels)\n",
        "\n",
        "      metric = dice_metric.aggregate().item()\n",
        "      dice_metric.reset()\n",
        "\n",
        "      metric_values.append(metric)\n",
        "\n",
        "      if metric > best_metric:\n",
        "        best_metric = metric\n",
        "        best_metric_epoch = epoch +1\n",
        "        torch.save(model.state_dict(), \"best_metric_model_segmentation3d_dict.pth\")\n",
        "        print(\"saved new best metric model\")\n",
        "      writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
        "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
        "      plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
        "      plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
        "      plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA7QHe2w9kPF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MONAI_tutorial(3D_seg).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7PaONGCDMVLVWvbN/lIec",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}